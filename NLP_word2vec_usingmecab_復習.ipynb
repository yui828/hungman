{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_word2vec_usingmecab 復習.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "XN789nBjlPI6"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yui828/hungman/blob/master/NLP_word2vec_usingmecab_%E5%BE%A9%E7%BF%92.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3my0cErlPIN"
      },
      "source": [
        "# 単語のベクトル化\n",
        "単語のベクトル化は、以下の順に行います。\n",
        "\n",
        "1. 前処理\n",
        "2. word2vecモデルを学習\n",
        "\n",
        "本ノートブックでは、Day1で利用したWikipedia のデータを利用して、単語のベクトル化を行います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iTp6HeIlPIP"
      },
      "source": [
        "!pip install gensim\n",
        "!apt install aptitude\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3==0.7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLeTjPXglPIT"
      },
      "source": [
        "import MeCab\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import unicodedata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6CRm0V5lPIV"
      },
      "source": [
        "## データの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SnUNs8_mrsa"
      },
      "source": [
        "# データのダウンロード\n",
        "!wget https://basic-unstructured-data.s3-ap-northeast-1.amazonaws.com/unstructured-data-day2/data.zip\n",
        "!unzip data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF0pPIuDlPIV",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e40af8b2-ff87-45ca-85d6-77e702e3b8dc"
      },
      "source": [
        "train = pd.read_csv(\"data/train.csv\")\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>世界の映画祭で話題沸騰！インドネシアの壮絶バイオレンス・アクション『ザ・レイド』予告編が解禁...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>冬の女子会は特製「薬膳火鍋」に決定！美味しく食べてポッカポカ本格的な寒さを感じるこの季節。「...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012年・夏の浴衣スタイルのカギは帯！夏といえば浴衣。「そろそろ新しい浴衣を買おうかな」と...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>インタビュー：武田修宏さん「結婚するならセリエAクラスの女性がいい」少年時代から天才サッカー...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>「ポケモン」や「ONE PIECE」と同じ賞を獲得したキモかわいいキャラが全国に「クサマダラ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  世界の映画祭で話題沸騰！インドネシアの壮絶バイオレンス・アクション『ザ・レイド』予告編が解禁...      1\n",
              "1  冬の女子会は特製「薬膳火鍋」に決定！美味しく食べてポッカポカ本格的な寒さを感じるこの季節。「...      2\n",
              "2  2012年・夏の浴衣スタイルのカギは帯！夏といえば浴衣。「そろそろ新しい浴衣を買おうかな」と...      2\n",
              "3  インタビュー：武田修宏さん「結婚するならセリエAクラスの女性がいい」少年時代から天才サッカー...      2\n",
              "4  「ポケモン」や「ONE PIECE」と同じ賞を獲得したキモかわいいキャラが全国に「クサマダラ...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF8-aKHylPIX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "10302b76-b938-44d4-d4bf-41e110b4725a"
      },
      "source": [
        "test = pd.read_csv(\"data/test.csv\")\n",
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>【Sports Watch】元代表二人によるカメルーン戦の予想は？TBSの報道番組「NEWS...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>若槻千夏に激似!? 女子バレーのニューヒロイン新鍋理沙バレーボールのW杯が開幕し、ロンドン五...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ソーシャルの今が分かる！ヤフーの「話題なう」ってなに？ヤフーは、Twitterなどのソーシャ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>もう一つのユーロ2012美女ばかりの観客席には選手の彼女も!?連日連夜熱戦が展開されているサ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>元日本代表監督の岡田武史氏、杭州緑城の監督に決定日本代表の前監督である岡田武史氏が15日、中...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  【Sports Watch】元代表二人によるカメルーン戦の予想は？TBSの報道番組「NEWS...      3\n",
              "1  若槻千夏に激似!? 女子バレーのニューヒロイン新鍋理沙バレーボールのW杯が開幕し、ロンドン五...      3\n",
              "2  ソーシャルの今が分かる！ヤフーの「話題なう」ってなに？ヤフーは、Twitterなどのソーシャ...      0\n",
              "3  もう一つのユーロ2012美女ばかりの観客席には選手の彼女も!?連日連夜熱戦が展開されているサ...      3\n",
              "4  元日本代表監督の岡田武史氏、杭州緑城の監督に決定日本代表の前監督である岡田武史氏が15日、中...      3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-t0okCllPIZ"
      },
      "source": [
        "## 正規化\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHC8HbOXlPIZ"
      },
      "source": [
        "train[\"text\"] = train[\"text\"].str.normalize(\"NFKC\")\n",
        "test[\"text\"] = test[\"text\"].str.normalize(\"NFKC\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRwOPCTdlPIb"
      },
      "source": [
        "今回は練習のために\"「」\"と\"『』\"の区別がないので、統一化してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qokZqD0glPIc"
      },
      "source": [
        "unify_dic = {\n",
        "    '『': '「',\n",
        "    '』': '」'\n",
        "}\n",
        "\n",
        "\n",
        "def unify_str(x):\n",
        "    dic_for_unify = str.maketrans(unify_dic)\n",
        "    x = x.translate(dic_for_unify)\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O542Kd3SljnH"
      },
      "source": [
        "train[\"text\"] = train[\"text\"].apply(unify_str)\n",
        "test[\"text\"] = test[\"text\"].apply(unify_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRAm884glPIe"
      },
      "source": [
        "## その他前処理\n",
        "---\n",
        "### 文書と関係のない記号の削除\n",
        "\n",
        "```In [1]: df[\"text\"][2][:20]\n",
        "Out[2]: '理性 理性(りせい、→→→)とは、人間に'\n",
        "```\n",
        "\n",
        "のような\"→\"は文書と関係ないと考えることができるので除去する。<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rST39kdKlPIe"
      },
      "source": [
        "stop_words = [\"→\", \"←\", \"?\", \"」\", \"「\", \":\", \"!\"]  # 適当な文字を設定\n",
        "\n",
        "\n",
        "def remove_stop_words(x):\n",
        "    for s in stop_words:\n",
        "        x = x.replace(s, '')\n",
        "    return x\n",
        "\n",
        "\n",
        "train[\"text\"] = train[\"text\"].apply(remove_stop_words)\n",
        "test[\"text\"] = test[\"text\"].apply(remove_stop_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ1erC7slPIg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e36ee0a9-8658-40d1-ff02-bb8badc3769e"
      },
      "source": [
        "train[\"text\"].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    世界の映画祭で話題沸騰インドネシアの壮絶バイオレンス・アクションザ・レイド予告編が解禁インド...\n",
              "1    冬の女子会は特製薬膳火鍋に決定美味しく食べてポッカポカ本格的な寒さを感じるこの季節。何が食べ...\n",
              "2    2012年・夏の浴衣スタイルのカギは帯夏といえば浴衣。そろそろ新しい浴衣を買おうかなと、思っ...\n",
              "3    インタビュー武田修宏さん結婚するならセリエAクラスの女性がいい少年時代から天才サッカー少年と...\n",
              "4    ポケモンやONE PIECEと同じ賞を獲得したキモかわいいキャラが全国にクサマダラオオコビト...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj_ZCmozlPIi"
      },
      "source": [
        "## 形態素解析\n",
        "---\n",
        "\n",
        "mecab を利用した形態素解析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyDUM7i-lPIw"
      },
      "source": [
        "def get_surfaces(text):\n",
        "    result = []\n",
        "    node = mecab.parseToNode(text)\n",
        "    while node:\n",
        "        if not node.feature.startswith(\"BOS/EOS\") and \\\n",
        "          not node.feature.startswith(\"助詞\") and \\\n",
        "          not node.feature.startswith(\"助動詞\") and \\\n",
        "          not node.feature.startswith(\"記号\"):\n",
        "            result.append(node.surface)\n",
        "        node = node.next\n",
        "    return \" \".join(result)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qa8_dAMmVCR"
      },
      "source": [
        "mecab = MeCab.Tagger()\n",
        "# バグ回避用\n",
        "mecab.parse(\"\")\n",
        "\n",
        "train['text_tokenized'] = train['text'].apply(get_surfaces)\n",
        "test['text_tokenized'] = test['text'].apply(get_surfaces)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNybrGprmcza",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "06768024-2fb7-4c8d-d992-3e2bc55ebecf"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>text_tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>世界の映画祭で話題沸騰インドネシアの壮絶バイオレンス・アクションザ・レイド予告編が解禁インド...</td>\n",
              "      <td>1</td>\n",
              "      <td>世界 映画 祭 話題 沸騰 インドネシア 壮絶 バイオレンス・アクションザ・レイド 予告編 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>冬の女子会は特製薬膳火鍋に決定美味しく食べてポッカポカ本格的な寒さを感じるこの季節。何が食べ...</td>\n",
              "      <td>2</td>\n",
              "      <td>冬 女子 会 特製 薬 膳 火 鍋 決定 美味しく 食べ ポッカポカ 本格 的 寒 さ 感じ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012年・夏の浴衣スタイルのカギは帯夏といえば浴衣。そろそろ新しい浴衣を買おうかなと、思っ...</td>\n",
              "      <td>2</td>\n",
              "      <td>2012 年 夏 浴衣 スタイル カギ 帯 夏 いえ 浴衣 そろそろ 新しい 浴衣 買お 思...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>インタビュー武田修宏さん結婚するならセリエAクラスの女性がいい少年時代から天才サッカー少年と...</td>\n",
              "      <td>2</td>\n",
              "      <td>インタビュー 武田 修 宏 さん 結婚 する セ リエ A クラス 女性 いい 少年 時代 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ポケモンやONE PIECEと同じ賞を獲得したキモかわいいキャラが全国にクサマダラオオコビト...</td>\n",
              "      <td>1</td>\n",
              "      <td>ポケモン ONE PIECE 同じ 賞 獲得 し キモ かわいい キャラ 全国 クサマダラオ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                     text_tokenized\n",
              "0  世界の映画祭で話題沸騰インドネシアの壮絶バイオレンス・アクションザ・レイド予告編が解禁インド...  ...  世界 映画 祭 話題 沸騰 インドネシア 壮絶 バイオレンス・アクションザ・レイド 予告編 ...\n",
              "1  冬の女子会は特製薬膳火鍋に決定美味しく食べてポッカポカ本格的な寒さを感じるこの季節。何が食べ...  ...  冬 女子 会 特製 薬 膳 火 鍋 決定 美味しく 食べ ポッカポカ 本格 的 寒 さ 感じ...\n",
              "2  2012年・夏の浴衣スタイルのカギは帯夏といえば浴衣。そろそろ新しい浴衣を買おうかなと、思っ...  ...  2012 年 夏 浴衣 スタイル カギ 帯 夏 いえ 浴衣 そろそろ 新しい 浴衣 買お 思...\n",
              "3  インタビュー武田修宏さん結婚するならセリエAクラスの女性がいい少年時代から天才サッカー少年と...  ...  インタビュー 武田 修 宏 さん 結婚 する セ リエ A クラス 女性 いい 少年 時代 ...\n",
              "4  ポケモンやONE PIECEと同じ賞を獲得したキモかわいいキャラが全国にクサマダラオオコビト...  ...  ポケモン ONE PIECE 同じ 賞 獲得 し キモ かわいい キャラ 全国 クサマダラオ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiqT07sZmm4S"
      },
      "source": [
        "## 特定の文字列を各文書から削除する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaZcH55Xms4G"
      },
      "source": [
        "def remove_stop_words(sentence):\n",
        "    stop_words = [\"その\", \"ため\"] # 適当な文字を設定\n",
        "    for s in stop_words:\n",
        "        sentence = sentence.replace(s, '')\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DoexZnCmvhz"
      },
      "source": [
        "train[\"text_tokenized\"] = train[\"text_tokenized\"].apply(remove_stop_words)\n",
        "test[\"text_tokenized\"] = test[\"text_tokenized\"].apply(remove_stop_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w4nExWdlPIx"
      },
      "source": [
        "## ライブラリのインポート"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82z3GogUlPIy"
      },
      "source": [
        "from gensim.models import word2vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6nfgwDdlPI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9acbfe0-e56f-4bf9-b98c-be9d8daec010"
      },
      "source": [
        "# 【ご参考】Phrasesを適用し頻出する単語のペアを1フレーズに変換する\n",
        "# 例えば「データミックス」をjanomeで分かち書きすると、辞書登録がなければ「データ」と「ミックス」に分解されます。<br>\n",
        "# しかし文書内に「データミックス」が頻出する場合は、「データ」と「ミックス」を「_」でつないで「データ_ミックス」\n",
        "# という1単語にします。\n",
        "\n",
        "from gensim.test.utils import datapath\n",
        "from gensim.models.word2vec import Text8Corpus\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "\n",
        "sentences = Text8Corpus(datapath('testcorpus.txt'))\n",
        "phrases = Phrases(sentences, min_count=1, threshold=1)  # train model\n",
        "phrases[[u'trees', u'graph', u'minors']]  # apply model to sentence\n",
        "# 'trees'と'graph'が_で繋がり、1単語になる\n",
        "\n",
        "# 参考URL\n",
        "# https://radimrehurek.com/gensim/models/phrases.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['trees_graph', 'minors']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRSOVBpBlinv",
        "outputId": "ddcd8585-8c53-4cc3-de92-7f00ac098ead"
      },
      "source": [
        "train[\"text_tokenized\"].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    世界 映画 祭 話題 沸騰 インドネシア 壮絶 バイオレンス・アクションザ・レイド 予告編 ...\n",
              "1    冬 女子 会 特製 薬 膳 火 鍋 決定 美味しく 食べ ポッカポカ 本格 的 寒 さ 感じ...\n",
              "2    2012 年 夏 浴衣 スタイル カギ 帯 夏 いえ 浴衣 そろそろ 新しい 浴衣 買お 思...\n",
              "3    インタビュー 武田 修 宏 さん 結婚 する セ リエ A クラス 女性 いい 少年 時代 ...\n",
              "4    ポケモン ONE PIECE 同じ 賞 獲得 し キモ かわいい キャラ 全国 クサマダラオ...\n",
              "Name: text_tokenized, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtJDiERSlPI2"
      },
      "source": [
        "### gensimのword2vecに渡せる形に変換"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6veCyQplPI2"
      },
      "source": [
        "sentences = [token.split(\" \") for token in train.text_tokenized]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epAcEE4hEuln"
      },
      "source": [
        "*   sentencesには2785個のリストがある\n",
        "*   sentences = [[0行目の文書の単語],[1行目‥],　....]]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-OMWWghcCpu",
        "outputId": "a0114462-13d3-4c25-cdae-7c4056d20800"
      },
      "source": [
        "len(sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2785"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o06KzZg3Dd3f"
      },
      "source": [
        "sentences[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN789nBjlPI6"
      },
      "source": [
        "### モデルの学習\n",
        "gensimのword2vecを利用し以下2モデルの実装を行います\n",
        "- CBOW(Continuous Bag-of-Words)\n",
        "- Skip-gram\n",
        "\n",
        "#### gensimのword2vecの主な引数\n",
        "\n",
        "|<center>引数</center>|<center>詳細</center>|\n",
        "| --- | --- |\n",
        "|<center>sg</center>|<div style=\"text-align: left;\">1を選べばskip-gram、0ならばCBOW</div>|\n",
        "|<center>size</center>|<div style=\"text-align: left;\">特徴ベクトルの次元数の設定。<br>sizeの値が大きいほど次元数が大きくなるので、表現力が上がる。<br>しかしsizeの値を大きくすると、計算時間がかかったり、メモリ占有率が上がったりする。</div>|\n",
        "|<center>min_count</center>|<div style=\"text-align: left;\">一定の頻度以下の単語を除外する際の値を設定する。<br>学習データの文書数とも関連する。一定頻度出現する単語を直接確認し、適切だと思われる値を設定する。</div>|\n",
        "|<center>window</center>|<div style=\"text-align: left;\">学習に利用する周辺単語の範囲を指定する。<br>値を設定する際は文書の特徴を見て判断するのが良い。<br>例えばニュース記事や説明書によって、予測する単語が関連する範囲が変わると思われるため。</div>|\n",
        "|<center>negative</center>|<div style=\"text-align: left;\">0よりも大きければネガティブサンプリングが用いられる。<br>0であればネガティブサンプリングが適用されない。</div>|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTNS-EAzlPI7"
      },
      "source": [
        "### まずはCBOWモデルの作成をします"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggHXcprqlPI7"
      },
      "source": [
        "# CBOWモデルの学習\n",
        "cbow_model = word2vec.Word2Vec(sentences,\n",
        "                               sg=0,\n",
        "                               size=250,\n",
        "                               min_count=10,\n",
        "                               window=15,\n",
        "                               seed=1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15yiikSmlPI-"
      },
      "source": [
        "# 作成したモデルの保存\n",
        "cbow_model.save(\"cbow_w2v.model\")\n",
        "# saveしたモデルを読み込む時は\n",
        "# model = word2vec.Word2Vec.load(\"./w2v.model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyBZMu-UlPJA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "6c3bd706-b971-41e3-b3e8-39d63aaf091e"
      },
      "source": [
        "# 映画と似たキーワードを見つけていきます。\n",
        "# ここで記載しているscoreは、単語同士のコサイン類似度です。\n",
        "pd.DataFrame(cbow_model.wv.most_similar(\n",
        "    positive=['映画']), columns=[\"keyword\", \"score\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>keyword</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>劇場</td>\n",
              "      <td>0.814640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>キセキ</td>\n",
              "      <td>0.798916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ドラマ</td>\n",
              "      <td>0.797846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>観る</td>\n",
              "      <td>0.794280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>名作</td>\n",
              "      <td>0.786865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ひみ</td>\n",
              "      <td>0.775069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>観</td>\n",
              "      <td>0.774080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>カンタ</td>\n",
              "      <td>0.772750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>エンター</td>\n",
              "      <td>0.770537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ベルセルク</td>\n",
              "      <td>0.762268</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  keyword     score\n",
              "0      劇場  0.814640\n",
              "1     キセキ  0.798916\n",
              "2     ドラマ  0.797846\n",
              "3      観る  0.794280\n",
              "4      名作  0.786865\n",
              "5      ひみ  0.775069\n",
              "6       観  0.774080\n",
              "7     カンタ  0.772750\n",
              "8    エンター  0.770537\n",
              "9   ベルセルク  0.762268"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE-_LVRblPJC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "3cdce6a7-0ded-49cc-a826-b224cea11fd5"
      },
      "source": [
        "# 結婚と似たキーワードを見つけていきます。\n",
        "pd.DataFrame(cbow_model.wv.most_similar(\n",
        "    positive=['結婚']), columns=[\"keyword\", \"score\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>keyword</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>彼氏</td>\n",
              "      <td>0.898464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>初対面</td>\n",
              "      <td>0.840336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>付き合い</td>\n",
              "      <td>0.809384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>相談</td>\n",
              "      <td>0.808942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ダメ</td>\n",
              "      <td>0.790987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>意外</td>\n",
              "      <td>0.785790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>寂しい</td>\n",
              "      <td>0.778444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>振り返り</td>\n",
              "      <td>0.775328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>浮気</td>\n",
              "      <td>0.773200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>質問</td>\n",
              "      <td>0.754491</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  keyword     score\n",
              "0      彼氏  0.898464\n",
              "1     初対面  0.840336\n",
              "2    付き合い  0.809384\n",
              "3      相談  0.808942\n",
              "4      ダメ  0.790987\n",
              "5      意外  0.785790\n",
              "6     寂しい  0.778444\n",
              "7    振り返り  0.775328\n",
              "8      浮気  0.773200\n",
              "9      質問  0.754491"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GZMukVylPJI"
      },
      "source": [
        "### Skip-gramモデルも作成してみましょう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8u4K3qElPJI"
      },
      "source": [
        "# skip-gramモデルの学習\n",
        "skipgram_model = word2vec.Word2Vec(sentences,\n",
        "                                   sg=1,\n",
        "                                   size=250,\n",
        "                                   min_count=10,\n",
        "                                   window=15, seed=1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30CRS5SOlPJK"
      },
      "source": [
        "# 作成したモデルの保存\n",
        "skipgram_model.save(\"skipgram_w2v.model\")\n",
        "# saveしたモデルを読み込む時は\n",
        "# model = word2vec.Word2Vec.load(\"./skipgram_w2v.model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kRIGK2blPJL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "5505c724-76c0-41b8-cc84-c7ac9c526e6c"
      },
      "source": [
        "# 映画と似たキーワードを見つけていきます。\n",
        "# ここで記載しているscoreは、単語同士のコサイン類似度です。\n",
        "pd.DataFrame(skipgram_model.wv.most_similar(\n",
        "    positive=['映画']), columns=[\"keyword\", \"score\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>keyword</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ウルトラマンサーガ</td>\n",
              "      <td>0.620860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ゾンビ</td>\n",
              "      <td>0.618450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>マサキ</td>\n",
              "      <td>0.600423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>マダガスカル</td>\n",
              "      <td>0.597838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>蘇る</td>\n",
              "      <td>0.597154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>エンタテイメント</td>\n",
              "      <td>0.589182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ビビビ</td>\n",
              "      <td>0.588942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>キツツキ</td>\n",
              "      <td>0.585571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>GW</td>\n",
              "      <td>0.585375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>洋画</td>\n",
              "      <td>0.584881</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     keyword     score\n",
              "0  ウルトラマンサーガ  0.620860\n",
              "1        ゾンビ  0.618450\n",
              "2        マサキ  0.600423\n",
              "3     マダガスカル  0.597838\n",
              "4         蘇る  0.597154\n",
              "5   エンタテイメント  0.589182\n",
              "6        ビビビ  0.588942\n",
              "7       キツツキ  0.585571\n",
              "8         GW  0.585375\n",
              "9         洋画  0.584881"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr6bz2kXlPJN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "d6dd524c-94fb-48b0-a8f6-08f43fd284c5"
      },
      "source": [
        "# 結婚と似たキーワードを見つけていきます。\n",
        "pd.DataFrame(skipgram_model.wv.most_similar(\n",
        "    positive=['結婚']), columns=[\"keyword\", \"score\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>keyword</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>独身</td>\n",
              "      <td>0.687369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>出産</td>\n",
              "      <td>0.678187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>付き合っ</td>\n",
              "      <td>0.677122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>交際</td>\n",
              "      <td>0.676919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>バツ</td>\n",
              "      <td>0.662746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>婚</td>\n",
              "      <td>0.649710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>白河</td>\n",
              "      <td>0.645941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>年上</td>\n",
              "      <td>0.642887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>桃子</td>\n",
              "      <td>0.640592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>プロポーズ</td>\n",
              "      <td>0.638906</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  keyword     score\n",
              "0      独身  0.687369\n",
              "1      出産  0.678187\n",
              "2    付き合っ  0.677122\n",
              "3      交際  0.676919\n",
              "4      バツ  0.662746\n",
              "5       婚  0.649710\n",
              "6      白河  0.645941\n",
              "7      年上  0.642887\n",
              "8      桃子  0.640592\n",
              "9   プロポーズ  0.638906"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8bc_3ZClPJX"
      },
      "source": [
        "## 文書のベクトル化\n",
        "---\n",
        "単語のベクトル化するモデルは、前述のコードで作成しました。\n",
        "次は作成したword2vecモデルを活用して、文書のベクトル化を行いましょう。\n",
        "手順としては以下の通りです。\n",
        "1. 抽出された各単語を、作成したword2Vecによってベクトル化\n",
        "2. 変換された各単語ベクトルの平均をとり、その結果得られたベクトルを記事のベクトルとする\n",
        "\n",
        "\n",
        "そして文書のベクトル化ができたら、テキスト分類を行いましょう。\n",
        "テキスト情報を上記ステップで定量化することで、テキストをカテゴリー別に分類してみましょう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3NwSO-BlPJX"
      },
      "source": [
        "\"\"\"\n",
        "1. 抽出された各単語を、作成したword2Vecによってベクトル化\n",
        "2. 変換された各単語ベクトルの平均をとり、その結果得られたベクトルを記事のベクトルとする\n",
        "上記2ステップを実行する関数を作成\n",
        "\"\"\"\n",
        "\n",
        "num_features = 250\n",
        "\n",
        "\n",
        "def avg_document_vector(data, num_features):\n",
        "    document_vec = np.zeros((len(data), num_features))\n",
        "    for i, doc_word_list in enumerate(data):\n",
        "        feature_vec = np.zeros((num_features,), dtype=\"float32\")\n",
        "        for word in doc_word_list:\n",
        "            try:\n",
        "                feature_vec = np.add(\n",
        "                    feature_vec, skipgram_model.wv.__getitem__(word))\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        feature_vec = np.divide(feature_vec, len(doc_word_list))\n",
        "        document_vec[i] = feature_vec\n",
        "    return document_vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZqc1dTWlPJZ"
      },
      "source": [
        "df[\"text\"]を変換したデータ(sentences)に対して\n",
        "1. 抽出された各単語を、作成したword2Vecによってベクトル化\n",
        "2. 変換された各単語ベクトルの平均をとり、その結果得られたベクトルを記事のベクトルとする\n",
        "\n",
        "を実施する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY61YvkWlPJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85131d8a-9a88-4fe3-aa2b-30ad7c4f80bb"
      },
      "source": [
        "# データイメージ参考\n",
        "sentences[0][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['世界', '映画', '祭', '話題', '沸騰', 'インドネシア', '壮絶', 'バイオレンス・アクションザ・レイド', '予告編', '解禁']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRQTJTqnlPJc"
      },
      "source": [
        "X = avg_document_vector(data=sentences, num_features=250)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kObiEnyAlPJe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93c0675a-6f74-4745-b187-7d82ea05cfa2"
      },
      "source": [
        "# 行が文書なので2785\n",
        "# 列がモデル作成時の特徴ベクトルの次元(size)なので250 となる\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2785, 250)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUECMkzMlPJx"
      },
      "source": [
        "## テストデータの学習済みword2vecを活用した文書ベクトル化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgDEuIYplPJx"
      },
      "source": [
        "# gensimのword2vecに渡せる形に変換\n",
        "test_sentences = [token.split(\" \") for token in test.text_tokenized]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxBWvcSNlPJ4"
      },
      "source": [
        "X_test = avg_document_vector(data=test_sentences, num_features=250)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IuRFn5JlPKA"
      },
      "source": [
        "## 分類器の適用・比較\n",
        "文書のベクトル化ができたら、後はこれまでやってきた機械学習と同様です。\n",
        "\n",
        "いくつかの分類器で、性能を比較してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9a7BGVLlPKB"
      },
      "source": [
        "from collections import Counter\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR2JhqMylPKK"
      },
      "source": [
        "# Accuracy, Precision/Recall/F-score/Support, Confusion Matrix を表示\n",
        "def show_evaluation_metrics(y_true, y_pred):\n",
        "    print(\"Accuracy:\")\n",
        "    print(accuracy_score(y_true, y_pred))\n",
        "    print()\n",
        "\n",
        "    print(\"Report:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "    print(\"Confusion matrix:\")\n",
        "    print(confusion_matrix(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrysKsFWlPKL"
      },
      "source": [
        "### ロジスティック回帰"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en_Q8SNIlPKM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d61354de-1335-41b2-cc44-2b27b14cba59"
      },
      "source": [
        "clf_lr = LogisticRegression(n_jobs=-1)\n",
        "clf_lr.fit(X, train[\"label\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=-1, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWaMeomElPKN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc61c09d-99fc-46c1-dddf-f1b069d23968"
      },
      "source": [
        "clf_lr.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 0, 3, 3, 0, 1, 1, 0, 0, 1, 1, 0, 1, 2, 1, 0, 0, 3, 2, 2, 0,\n",
              "       0, 0, 3, 1, 2, 0, 1, 0, 0, 3, 0, 1, 2, 3, 2, 3, 0, 1, 3, 1, 0, 3,\n",
              "       1, 3, 2, 0, 2, 3, 1, 3, 1, 0, 1, 0, 3, 0, 3, 1, 3, 1, 1, 1, 0, 3,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 3, 1, 1, 3, 3, 2, 2, 2, 0, 0, 0, 3, 0, 1,\n",
              "       3, 3, 0, 0, 3, 1, 1, 3, 2, 1, 0, 3, 2, 3, 1, 1, 3, 3, 0, 2, 3, 2,\n",
              "       1, 1, 3, 0, 2, 3, 1, 0, 1, 0, 0, 2, 3, 1, 3, 2, 1, 2, 3, 0, 2, 2,\n",
              "       0, 0, 3, 0, 0, 0, 3, 1, 1, 1, 3, 0, 2, 3, 3, 3, 0, 1, 0, 0, 2, 0,\n",
              "       0, 0, 2, 3, 1, 2, 0, 0, 1, 0, 3, 3, 3, 2, 0, 1, 3, 3, 1, 3, 1, 0,\n",
              "       1, 1, 2, 1, 3, 1, 3, 3, 2, 2, 2, 2, 0, 1, 2, 1, 3, 3, 0, 2, 3, 3,\n",
              "       1, 2, 3, 1, 2, 0, 3, 2, 0, 0, 0, 1, 0, 3, 1, 3, 0, 0, 1, 1, 2, 3,\n",
              "       0, 2, 2, 2, 1, 1, 3, 0, 3, 1, 1, 2, 1, 3, 3, 0, 3, 3, 1, 1, 3, 2,\n",
              "       1, 0, 3, 0, 0, 2, 1, 3, 0, 3, 2, 0, 0, 1, 3, 1, 0, 0, 0, 0, 2, 0,\n",
              "       1, 3, 2, 1, 2, 3, 2, 2, 2, 3, 1, 1, 1, 0, 1, 2, 0, 3, 0, 3, 1, 3,\n",
              "       0, 0, 3, 0, 3, 3, 3, 2, 0, 0, 0, 3, 0, 3, 2, 2, 0, 1, 3, 0, 0, 3,\n",
              "       2, 3, 3, 2, 1, 0, 1, 3, 1, 3, 2, 3, 0, 3, 0, 3, 3, 3, 0, 3, 0, 3,\n",
              "       1, 1, 3, 0, 2, 1, 3, 2, 3, 3, 0, 1, 1, 1, 0, 1, 2, 1, 1, 3, 0, 2,\n",
              "       3, 1, 2, 2, 1, 2, 1, 3, 1, 0, 2, 1, 3, 1, 3, 0, 1, 0, 2, 3, 1, 2,\n",
              "       1, 1, 0, 3, 2, 0, 0, 3, 2, 1, 2, 0, 3, 1, 3, 3, 2, 2, 0, 2, 0, 2,\n",
              "       1, 1, 2, 1, 3, 1, 2, 0, 0, 1, 0, 0, 1, 2, 3, 3, 2, 0, 1, 0, 0, 0,\n",
              "       0, 0, 3, 1, 2, 1, 1, 0, 1, 3, 2, 2, 3, 2, 0, 1, 0, 0, 0, 2, 3, 3,\n",
              "       1, 2, 1, 1, 3, 1, 2, 0, 3, 1, 3, 3, 3, 0, 2, 2, 1, 2, 0, 1, 2, 0,\n",
              "       0, 1, 2, 0, 2, 0, 1, 2, 1, 2, 2, 3, 0, 3, 1, 0, 0, 3, 3, 1, 0, 3,\n",
              "       3, 3, 0, 3, 3, 1, 1, 0, 3, 2, 0, 3, 0, 3, 3, 1, 1, 0, 3, 2, 2, 3,\n",
              "       2, 1, 3, 2, 2, 1, 0, 1, 3, 2, 3, 2, 1, 0, 1, 3, 0, 1, 1, 1, 0, 2,\n",
              "       2, 3, 2, 2, 0, 0, 3, 2, 0, 2, 0, 0, 3, 0, 2, 1, 1, 3, 3, 0, 1, 2,\n",
              "       1, 2, 1, 1, 0, 0, 3, 0, 0, 1, 2, 1, 0, 1, 3, 3, 3, 2, 3, 2, 1, 1,\n",
              "       2, 1, 1, 2, 1, 3, 3, 1, 0, 2, 2, 1, 0, 2, 1, 0, 3, 2, 3, 1, 2, 1,\n",
              "       0, 2, 0, 2, 0, 2, 3, 3, 1, 1, 3, 2, 1, 0, 1, 3, 3, 3, 0, 2, 1, 1,\n",
              "       3, 1, 0, 1, 0, 3, 2, 1, 3, 1, 0, 2, 3, 0, 3, 3, 2, 3, 1, 0, 2, 1,\n",
              "       1, 1, 2, 3, 1, 0, 3, 1, 2, 3, 1, 0, 3, 0, 2, 0, 2, 0, 3, 3, 2, 3,\n",
              "       2, 0, 3, 1, 2, 3, 0, 2, 0, 3, 0, 2, 2, 1, 3, 0, 3, 0, 2, 2, 3, 3,\n",
              "       1, 2, 2, 3, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOrKOY4tlPKP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6d84126-4588-4c7e-d713-c89b7f3759ad"
      },
      "source": [
        "y_test_pred = clf_lr.predict(X_test)\n",
        "show_evaluation_metrics(test[\"label\"], y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:\n",
            "0.9641319942611191\n",
            "\n",
            "Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97       183\n",
            "           1       0.93      0.98      0.95       173\n",
            "           2       0.95      0.91      0.93       155\n",
            "           3       0.99      0.99      0.99       186\n",
            "\n",
            "    accuracy                           0.96       697\n",
            "   macro avg       0.96      0.96      0.96       697\n",
            "weighted avg       0.96      0.96      0.96       697\n",
            "\n",
            "Confusion matrix:\n",
            "[[177   1   4   1]\n",
            " [  1 169   3   0]\n",
            " [  3  11 141   0]\n",
            " [  1   0   0 185]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om6tI82TlPKQ"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5I87-qGlPKR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "453d7578-5d96-41b5-c99d-ffb4938b079f"
      },
      "source": [
        "clf_rf = RandomForestClassifier(n_estimators=50, n_jobs=-1)\n",
        "clf_rf.fit(X, train[\"label\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
              "                       oob_score=False, random_state=None, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XrDjP5llPKS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbf09255-de8b-4f19-96d2-c120e9ed5ad9"
      },
      "source": [
        "y_test_pred = clf_rf.predict(X_test)\n",
        "show_evaluation_metrics(test[\"label\"], y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:\n",
            "0.9583931133428981\n",
            "\n",
            "Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.95      0.96       183\n",
            "           1       0.93      0.98      0.96       173\n",
            "           2       0.93      0.90      0.92       155\n",
            "           3       0.99      0.99      0.99       186\n",
            "\n",
            "    accuracy                           0.96       697\n",
            "   macro avg       0.96      0.96      0.96       697\n",
            "weighted avg       0.96      0.96      0.96       697\n",
            "\n",
            "Confusion matrix:\n",
            "[[174   1   8   0]\n",
            " [  1 170   2   0]\n",
            " [  3  11 140   1]\n",
            " [  2   0   0 184]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PDgV8JsuofK"
      },
      "source": [
        "# submitするためのcsvファイルを作成\n",
        "y_test_pred = clf_lr.predict_proba(test_tfidf)\n",
        "submissions = pd.DataFrame({\"Id\": list(test[\"Id\"]), \"polarity_flag\": y_test_pred[:, 1]})\n",
        "submissions.to_csv(\"submission_ny.csv\", index=False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrSAoU21v3uz"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}